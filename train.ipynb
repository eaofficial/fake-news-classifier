{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv(\"data/Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = pd.read_csv(\"data/True.csv\")\n",
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Creating list of index that do not have publication part\n",
    "unknown_publishers = []\n",
    "for index,row in enumerate(real.text.values):\n",
    "    try:\n",
    "        record = row.split(\" -\", maxsplit=1)\n",
    "        #if no text part is present, following will give error\n",
    "        record[1]\n",
    "        #if len of publication part is greater than 260\n",
    "        #following will give error, ensuring no text having \"-\" in between is counted\n",
    "        assert(len(record[0]) < 260)\n",
    "    except:\n",
    "        unknown_publishers.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3488     The White House on Wednesday disclosed a group...\n",
       "4358     Neil Gorsuch, President Donald Trump’s appoint...\n",
       "4465     WASHINGTON The clock began running out this we...\n",
       "5784     Federal appeals court judge Neil Gorsuch, the ...\n",
       "6660     Republican members of Congress are complaining...\n",
       "6823     Over the course of the U.S. presidential campa...\n",
       "7922     After going through a week reminiscent of Napo...\n",
       "8194     The following timeline charts the origin and s...\n",
       "8195     Global health officials are racing to better u...\n",
       "8247     U.S. President Barack Obama visited a street m...\n",
       "8465     ALGONAC, MICH.—Parker Fox drifted out of the D...\n",
       "8481     Global health officials are racing to better u...\n",
       "8482     The following timeline charts the origin and s...\n",
       "8505     Global health officials are racing to better u...\n",
       "8506     The following timeline charts the origin and s...\n",
       "8771     In a speech weighted with America’s complicate...\n",
       "8970                                                      \n",
       "9008     The following timeline charts the origin and s...\n",
       "9009     Global health officials are racing to better u...\n",
       "9307     It’s the near future, and North Korea’s regime...\n",
       "9618     GOP leaders have unleashed a stunning level of...\n",
       "9737     Caitlyn Jenner posted a video on Wednesday (Ap...\n",
       "10479    The Democratic and Republican nominees for the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hence we have a list of indices where publisher is not mentioned\n",
    "real.iloc[unknown_publishers].text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#we can see that text at index 8970 is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating publishers from the news text\n",
    "publisher = []\n",
    "tmp_text = []\n",
    "for index, row in enumerate(real.text.values):\n",
    "    if index in unknown_publishers:\n",
    "        # add text to tmp_text and \"unknown\" to publishers\n",
    "        #tmp_text.append(row)\n",
    "        tmp_text.append(row)\n",
    "        publisher.append(\"Unknown\")\n",
    "        continue\n",
    "    record = row.split(' -', maxsplit=1)\n",
    "    tmp_text.append(record[1])\n",
    "    publisher.append(record[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the dataframe by replacing text column by tmp_text and adding publisher column in df\n",
    "real['publisher'] = publisher\n",
    "real['text'] = tmp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del publisher, tmp_text, record, unknown_publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>The head of a conservative Republican faction...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>WASHINGTON (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>Transgender people will be allowed for the fi...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>WASHINGTON (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>The special counsel investigation of links be...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>WASHINGTON (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>Trump campaign adviser George Papadopoulos to...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>WASHINGTON (Reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>President Donald Trump called on the U.S. Pos...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0   The head of a conservative Republican faction...  politicsNews   \n",
       "1   Transgender people will be allowed for the fi...  politicsNews   \n",
       "2   The special counsel investigation of links be...  politicsNews   \n",
       "3   Trump campaign adviser George Papadopoulos to...  politicsNews   \n",
       "4   President Donald Trump called on the U.S. Pos...  politicsNews   \n",
       "\n",
       "                 date                     publisher  \n",
       "0  December 31, 2017           WASHINGTON (Reuters)  \n",
       "1  December 29, 2017           WASHINGTON (Reuters)  \n",
       "2  December 31, 2017           WASHINGTON (Reuters)  \n",
       "3  December 30, 2017           WASHINGTON (Reuters)  \n",
       "4  December 29, 2017   SEATTLE/WASHINGTON (Reuters)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8970]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for empty texts \n",
    "\n",
    "[index for index, text in enumerate(real.text.values) if str(text.strip()) == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.drop(8970, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of empty rows: 630\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>BALTIMORE BURNS: MARYLAND GOVERNOR BRINGS IN N...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 27, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21826</th>\n",
       "      <td>FULL VIDEO: THE BLOCKBUSTER INVESTIGATION INTO...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 25, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21827</th>\n",
       "      <td>(VIDEO) HILLARY CLINTON: RELIGIOUS BELIEFS MUS...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 25, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21857</th>\n",
       "      <td>(VIDEO)ICE PROTECTING OBAMA: WON’T RELEASE NAM...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21873</th>\n",
       "      <td>(VIDEO) HYSTERICAL SNL TAKE ON HILLARY’S ANNOU...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 12, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title text    subject  \\\n",
       "21816  BALTIMORE BURNS: MARYLAND GOVERNOR BRINGS IN N...       left-news   \n",
       "21826  FULL VIDEO: THE BLOCKBUSTER INVESTIGATION INTO...       left-news   \n",
       "21827  (VIDEO) HILLARY CLINTON: RELIGIOUS BELIEFS MUS...       left-news   \n",
       "21857  (VIDEO)ICE PROTECTING OBAMA: WON’T RELEASE NAM...       left-news   \n",
       "21873  (VIDEO) HYSTERICAL SNL TAKE ON HILLARY’S ANNOU...       left-news   \n",
       "\n",
       "               date  \n",
       "21816  Apr 27, 2015  \n",
       "21826  Apr 25, 2015  \n",
       "21827  Apr 25, 2015  \n",
       "21857  Apr 14, 2015  \n",
       "21873  Apr 12, 2015  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the same in fake news\n",
    "empty_fake_index = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']\n",
    "print(f\"No of empty rows: {len(empty_fake_index)}\")\n",
    "fake.iloc[empty_fake_index].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at publication Information\n",
    "# Checking if Some part of text has been included as publisher info... No such cases it seems :)\n",
    "\n",
    "# for name,count in real.publisher.value_counts().iteritems():\n",
    "#     print(f\"Name: {name}\\nCount: {count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding class info\n",
    "real['class'] = 1\n",
    "fake['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining title and text because in fake news some of the titles contains text also\n",
    "real['text'] = real['text'] + \" \" + real['title']\n",
    "fake['text'] = fake['text'] + \" \" + fake['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject is diffrent for real and fake thus dropping it\n",
    "# Also dropping Date, title and Publication\n",
    "real.drop([\"subject\", \"date\",\"title\",  \"publisher\"], axis=1, inplace=True)\n",
    "fake.drop([\"subject\", \"date\", \"title\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both into new dataframe\n",
    "data = real.append(fake, ignore_index=True)\n",
    "del real, fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download following if not downloaded\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n",
    "X = []\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "for par in data[\"text\"].values:\n",
    "    tmp = []\n",
    "    sentences = nltk.sent_tokenize(par)\n",
    "    for sent in sentences:\n",
    "        sent = sent.lower()\n",
    "        tokens = tokenizer.tokenize(sent)\n",
    "        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n",
    "        tmp.extend(filtered_words)\n",
    "    X.append(tmp)\n",
    "\n",
    "#del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 100\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences=X, size=EMBEDDING_DIM, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03159817, -0.03679837,  0.02834213,  0.03340937, -0.02590122,\n",
       "       -0.05862952,  0.01599212,  0.01199531, -0.07441131, -0.07457554,\n",
       "        0.03885771,  0.01571267,  0.0125641 ,  0.03980087,  0.05585509,\n",
       "       -0.00606662,  0.0263378 ,  0.02253428,  0.06532586, -0.02031444,\n",
       "       -0.01433898,  0.01356174, -0.01979356, -0.01610847,  0.01678284,\n",
       "        0.03633159,  0.06454521,  0.0634786 ,  0.00369098,  0.04137363,\n",
       "        0.03499714,  0.05780138,  0.02772401, -0.00847839, -0.02033838,\n",
       "       -0.02826664,  0.05737522,  0.00961463,  0.06300186,  0.05140311,\n",
       "       -0.06191216,  0.03010267, -0.0302725 , -0.08221912,  0.00839687,\n",
       "       -0.01213105, -0.05420544, -0.00236788,  0.00014751,  0.08358745,\n",
       "       -0.01534635,  0.0228162 , -0.00520066, -0.01081474,  0.06015006,\n",
       "       -0.01020659, -0.0834104 , -0.00390348, -0.02223338,  0.09387011,\n",
       "        0.0253583 , -0.0222803 ,  0.04952316, -0.01011371,  0.05378832,\n",
       "        0.02506652,  0.00796656, -0.02076262,  0.01648998, -0.03688773,\n",
       "       -0.00660921,  0.02583895, -0.0162013 , -0.02909702,  0.01803936,\n",
       "        0.03012553, -0.0312492 , -0.00648688,  0.01046941, -0.08512821,\n",
       "        0.03446754, -0.09238863,  0.00664914,  0.00054997, -0.06313651,\n",
       "        0.02694216,  0.02082639,  0.10279088,  0.05412924,  0.02810979,\n",
       "       -0.04853301, -0.04847567, -0.03881678,  0.05547415, -0.04097616,\n",
       "       -0.04617864, -0.08286797,  0.00185679,  0.05968551,  0.04215592],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see a sample vector for random word, lets say Corona \n",
    "w2v_model[\"corona\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comey', 0.7456110119819641),\n",
       " ('cia', 0.6158008575439453),\n",
       " ('investigators', 0.614845871925354),\n",
       " ('mueller', 0.613229513168335),\n",
       " ('investigation', 0.6057909727096558),\n",
       " ('investigations', 0.5760188102722168),\n",
       " ('doj', 0.5632096529006958),\n",
       " ('probe', 0.5538828372955322),\n",
       " ('leaks', 0.5385240316390991),\n",
       " ('nunes', 0.5340120196342468)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('fbi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('presidency', 0.6215769052505493),\n",
       " ('presidents', 0.5683609843254089),\n",
       " ('1eee3v0xd2', 0.5472301244735718),\n",
       " ('successor', 0.5379428863525391),\n",
       " ('administration', 0.5265040993690491),\n",
       " ('versa', 0.5147182941436768),\n",
       " ('biden', 0.5146135687828064),\n",
       " ('presidential', 0.5139675140380859),\n",
       " ('predecessor', 0.4606121778488159),\n",
       " ('trump', 0.4599958062171936)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nation', 0.8616493940353394),\n",
       " ('america', 0.6929206252098083),\n",
       " ('continent', 0.6141115427017212),\n",
       " ('world', 0.601699948310852),\n",
       " ('region', 0.5676153898239136),\n",
       " ('europe', 0.561434268951416),\n",
       " ('planet', 0.5589169263839722),\n",
       " ('us', 0.5529625415802002),\n",
       " ('societies', 0.5276421308517456),\n",
       " ('countries', 0.5226161479949951)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump -> 1\n",
      "said -> 2\n",
      "president -> 3\n",
      "would -> 4\n",
      "people -> 5\n",
      "one -> 6\n",
      "state -> 7\n",
      "new -> 8\n",
      "obama -> 9\n",
      "also -> 10\n"
     ]
    }
   ],
   "source": [
    "#Lets check few word to numerical replesentation\n",
    "#Mapping is preserved in dictionary -> word_index property of instance\n",
    "word_index = tokenizer.word_index\n",
    "for word, num in word_index.items():\n",
    "    print(f\"{word} -> {num}\")\n",
    "    if num == 10:\n",
    "        break        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For determining size of input...\n",
    "\n",
    "# Making histogram for no of words in news shows that most news article are under 700 words.\n",
    "# Lets keep each news small and truncate all news to 700 while tokenizing\n",
    "plt.hist([len(x) for x in X], bins=500)\n",
    "plt.show()\n",
    "\n",
    "# Its heavily skewed. There are news with 5000 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43982"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos = np.array([len(x) for x in X])\n",
    "len(nos[nos  < 700])\n",
    "# Out of 48k news, 44k have less than 700 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make all news to 700, adding padding to short ones and truncting long ones\n",
    "maxlen = 700\n",
    "X = pad_sequences(X, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
    "# Thus our vocab size inceeases by 1\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocab size + 0 for unknown words\n",
    "    vocab_size = len(vocab)+1\n",
    "    #inetialize weight matrix with all zeros\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting embedding vectors from word2vec and using it as weights of non-trainable keras embedding layer\n",
    "embedding_vectors = get_weight_matrix(w2v_model, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating layers for neural network model\n",
    "model = Sequential()\n",
    "#adding a non-trainable embedding layer as input layer\n",
    "model.add(Embedding(vocab_size, output_dim = EMBEDDING_DIM, weights = [embedding_vectors], input_length = maxlen, trainable=False))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "#del  embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 700, 100)          12224900  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 12,342,277\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 12,224,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23570 samples, validate on 10102 samples\n",
      "Epoch 1/6\n",
      "23570/23570 [==============================] - 506s 21ms/sample - loss: 0.0780 - acc: 0.9725 - val_loss: 0.0539 - val_acc: 0.9805\n",
      "Epoch 2/6\n",
      "23570/23570 [==============================] - 505s 21ms/sample - loss: 0.0319 - acc: 0.9892 - val_loss: 0.0354 - val_acc: 0.9889\n",
      "Epoch 3/6\n",
      "23570/23570 [==============================] - 495s 21ms/sample - loss: 0.0169 - acc: 0.9949 - val_loss: 0.0330 - val_acc: 0.9911\n",
      "Epoch 4/6\n",
      "23570/23570 [==============================] - 497s 21ms/sample - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0349 - val_acc: 0.9897\n",
      "Epoch 5/6\n",
      "23570/23570 [==============================] - 501s 21ms/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0390 - val_acc: 0.9896\n",
      "Epoch 6/6\n",
      "23570/23570 [==============================] - 507s 22ms/sample - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0350 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b5e629110>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.3, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction is in probability of news being real, so converting into classes\n",
    "# Class 0 (Fake) if predicted prob < 0.5, else class 1 (Real)\n",
    "y_pred = (model.predict(X_test) >= 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915367483296214"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      5848\n",
      "           1       0.99      0.99      0.99      5377\n",
      "\n",
      "    accuracy                           0.99     11225\n",
      "   macro avg       0.99      0.99      0.99     11225\n",
      "weighted avg       0.99      0.99      0.99     11225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('tokenizer.tk', 'wb') as tokenizer_file:\n",
    " \n",
    "  # Step 3\n",
    "  pickle.dump(tokenizer, tokenizer_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
